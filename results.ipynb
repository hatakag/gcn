{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\Downloads\\Study\\Graduation Research\\GCN\\gcn\\gcn\n"
     ]
    }
   ],
   "source": [
    "cd gcn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from gcn.utils import *\n",
    "from gcn.models import GCN, MLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed\n",
    "seed = 123\n",
    "np.random.seed(seed)\n",
    "tf.set_random_seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Settings\n",
    "flags = tf.app.flags\n",
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_string('f', '', 'kernel')\n",
    "flags.DEFINE_string('dataset', 'cora', 'Dataset string.')  # 'cora', 'citeseer', 'pubmed'\n",
    "flags.DEFINE_string('model', 'gcn', 'Model string.')  # 'gcn', 'gcn_cheby', 'dense'\n",
    "flags.DEFINE_float('learning_rate', 0.01, 'Initial learning rate.')\n",
    "flags.DEFINE_integer('epochs', 200, 'Number of epochs to train.')\n",
    "flags.DEFINE_integer('hidden1', 16, 'Number of units in hidden layer 1.')\n",
    "flags.DEFINE_float('dropout', 0.5, 'Dropout rate (1 - keep probability).')\n",
    "flags.DEFINE_float('weight_decay', 5e-4, 'Weight for L2 loss on embedding matrix.')\n",
    "flags.DEFINE_integer('early_stopping', 10, 'Tolerance for early stopping (# of epochs).')\n",
    "flags.DEFINE_integer('max_degree', 3, 'Maximum Chebyshev polynomial degree.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Downloads\\Study\\Graduation Research\\GCN\\gcn\\venv\\lib\\site-packages\\scipy\\sparse\\lil.py:512: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n  if not i.flags.writeable or i.dtype not in (np.int32, np.int64):\nD:\\Downloads\\Study\\Graduation Research\\GCN\\gcn\\venv\\lib\\site-packages\\scipy\\sparse\\lil.py:514: FutureWarning: future versions will not create a writeable array from broadcast_array. Set the writable flag explicitly to avoid this warning.\n  if not j.flags.writeable or j.dtype not in (np.int32, np.int64):\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "\"\"\"\n",
    "    Loads input data from gcn/data directory\n",
    "\n",
    "    ind.dataset_str.x => the feature vectors of the training instances as scipy.sparse.csr.csr_matrix object;\n",
    "    ind.dataset_str.tx => the feature vectors of the test instances as scipy.sparse.csr.csr_matrix object;\n",
    "    ind.dataset_str.allx => the feature vectors of both labeled and unlabeled training instances\n",
    "        (a superset of ind.dataset_str.x) as scipy.sparse.csr.csr_matrix object;\n",
    "    ind.dataset_str.y => the one-hot labels of the labeled training instances as numpy.ndarray object;\n",
    "    ind.dataset_str.ty => the one-hot labels of the test instances as numpy.ndarray object;\n",
    "    ind.dataset_str.ally => the labels for instances in ind.dataset_str.allx as numpy.ndarray object;\n",
    "    ind.dataset_str.graph => a dict in the format {index: [index_of_neighbor_nodes]} as collections.defaultdict\n",
    "        object;\n",
    "    ind.dataset_str.test.index => the indices of test instances in graph, for the inductive setting as list object.\n",
    "\n",
    "    All objects above must be saved using python pickle module.\n",
    "\n",
    "    :param dataset_str: Dataset name\n",
    "    :return: All data input files loaded (as well the training/test data). \n",
    "             Adjacent matrix, feature matrix, label matrix of each phase with corresponding mask\n",
    "\"\"\"\n",
    "\n",
    "adj, features, y_train, y_val, y_test, train_mask, val_mask, test_mask = load_data(FLAGS.dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[   0, 1274],\n        [   0, 1247],\n        [   0, 1194],\n        ...,\n        [2707,  329],\n        [2707,  186],\n        [2707,   19]], dtype=int32),\n array([0.11111111, 0.11111111, 0.11111111, ..., 0.07692308, 0.07692308,\n        0.07692308], dtype=float32),\n (2708, 1433))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some preprocessing\n",
    "features = preprocess_features(features)\n",
    "if FLAGS.model == 'gcn':\n",
    "    support = [preprocess_adj(adj)]\n",
    "    num_supports = 1\n",
    "    model_func = GCN\n",
    "elif FLAGS.model == 'gcn_cheby':\n",
    "    support = chebyshev_polynomials(adj, FLAGS.max_degree)\n",
    "    num_supports = 1 + FLAGS.max_degree\n",
    "    model_func = GCN\n",
    "elif FLAGS.model == 'dense':\n",
    "    support = [preprocess_adj(adj)]  # Not used\n",
    "    num_supports = 1\n",
    "    model_func = MLP\n",
    "else:\n",
    "    raise ValueError('Invalid argument for model: ' + str(FLAGS.model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[   0, 1274],\n        [   0, 1247],\n        [   0, 1194],\n        ...,\n        [2707,  329],\n        [2707,  186],\n        [2707,   19]], dtype=int32),\n array([0.11111111, 0.11111111, 0.11111111, ..., 0.07692308, 0.07692308,\n        0.07692308], dtype=float32),\n (2708, 1433))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define placeholders\n",
    "placeholders = {\n",
    "    'support': [tf.sparse_placeholder(tf.float32) for _ in range(num_supports)],\n",
    "    'features': tf.sparse_placeholder(tf.float32, shape=tf.constant(features[2], dtype=tf.int64)),\n",
    "    'labels': tf.placeholder(tf.float32, shape=(None, y_train.shape[1])),\n",
    "    'labels_mask': tf.placeholder(tf.int32),\n",
    "    'dropout': tf.placeholder_with_default(0., shape=()),\n",
    "    'num_features_nonzero': tf.placeholder(tf.int32)  # helper variable for sparse dropout\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Downloads\\Study\\Graduation Research\\GCN\\gcn\\venv\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nColocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Downloads\\Study\\Graduation Research\\GCN\\gcn\\gcn\\layers.py:170: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Downloads\\Study\\Graduation Research\\GCN\\gcn\\gcn\\metrics.py:6: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\n\nFuture major versions of TensorFlow will allow gradients to flow\ninto the labels input on backprop by default.\n\nSee `tf.nn.softmax_cross_entropy_with_logits_v2`.\n\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From D:\\Downloads\\Study\\Graduation Research\\GCN\\gcn\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\nInstructions for updating:\nUse tf.cast instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 train_loss= 1.95461 train_acc= 0.07857 val_loss= 1.95068 val_acc= 0.17600 time= 2.79149\nEpoch: 0002 train_loss= 1.94861 train_acc= 0.25714 val_loss= 1.94722 val_acc= 0.32400 time= 0.12093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0003 train_loss= 1.94277 train_acc= 0.50000 val_loss= 1.94340 val_acc= 0.43400 time= 0.10094\nEpoch: 0004 train_loss= 1.93624 train_acc= 0.55714 val_loss= 1.93984 val_acc= 0.45000 time= 0.15691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0005 train_loss= 1.92757 train_acc= 0.67857 val_loss= 1.93628 val_acc= 0.44200 time= 0.12893\nEpoch: 0006 train_loss= 1.92056 train_acc= 0.66429 val_loss= 1.93239 val_acc= 0.44600 time= 0.11151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0007 train_loss= 1.91186 train_acc= 0.64286 val_loss= 1.92828 val_acc= 0.44400 time= 0.09495\nEpoch: 0008 train_loss= 1.90454 train_acc= 0.62857 val_loss= 1.92421 val_acc= 0.44200 time= 0.09495\nEpoch:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0009 train_loss= 1.89406 train_acc= 0.70000 val_loss= 1.92011 val_acc= 0.45800 time= 0.08995\nEpoch: 0010 train_loss= 1.88493 train_acc= 0.70000 val_loss= 1.91599 val_acc= 0.47800 time= 0.09188\nEpoch: 0011 train_loss= 1.87616 train_acc="
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.74286 val_loss= 1.91180 val_acc= 0.51000 time= 0.08768\nEpoch: 0012 train_loss= 1.87072 train_acc= 0.73571 val_loss= 1.90748 val_acc= 0.52800 time= 0.11993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0013 train_loss= 1.86251 train_acc= 0.70714 val_loss= 1.90315 val_acc= 0.55200 time= 0.11394\nEpoch: 0014 train_loss= 1.84735 train_acc= 0.70714 val_loss= 1.89871 val_acc= 0.56400 time= 0.11191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0015 train_loss= 1.83780 train_acc= 0.72857 val_loss= 1.89422 val_acc= 0.57600 time= 0.09794\nEpoch: 0016 train_loss= 1.81915 train_acc= 0.77143 val_loss= 1.88969 val_acc= 0.57800 time= 0.09494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0017 train_loss= 1.81948 train_acc= 0.75714 val_loss= 1.88508 val_acc= 0.59000 time= 0.09494\nEpoch: 0018 train_loss= 1.81147 train_acc= 0.77143 val_loss= 1.88036 val_acc= 0.59000 time= 0.09195\nEpoch: 0019 train_loss= 1.78988 train_acc= 0.80000 val_loss= 1.87534 val_acc= 0.59800 time= 0.08795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0020 train_loss= 1.78313 train_acc= 0.76429 val_loss= 1.87020 val_acc= 0.60400 time= 0.08694\nEpoch: 0021 train_loss= 1.76766 train_acc= 0.80000 val_loss= 1.86487 val_acc= 0.60600 time= 0.11694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0022 train_loss= 1.74921 train_acc= 0.80714 val_loss= 1.85943 val_acc= 0.61000 time= 0.11096\nEpoch: 0023 train_loss= 1.74168 train_acc= 0.75000 val_loss= 1.85380 val_acc= 0.61400 time= 0.09243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0024 train_loss= 1.72814 train_acc= 0.77143 val_loss= 1.84797 val_acc= 0.61400 time= 0.11394\nEpoch: 0025 train_loss= 1.71721 train_acc= 0.78571 val_loss= 1.84191 val_acc= 0.61400 time= 0.09494\nEpoch: 0026 train_loss= 1.70792 train_acc= 0.82143 val_loss= 1.83568 val_acc= 0.62600 time= 0.09195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0027 train_loss= 1.68943 train_acc= 0.81429 val_loss= 1.82938 val_acc= 0.63000 time= 0.12093\nEpoch: 0028 train_loss= 1.67868 train_acc= 0.77143 val_loss= 1.82284 val_acc= 0.64400 time= 0.11293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0029 train_loss= 1.66631 train_acc= 0.81429 val_loss= 1.81602 val_acc= 0.65200 time= 0.10605\nEpoch: 0030 train_loss= 1.67101 train_acc= 0.80000 val_loss= 1.80893 val_acc= 0.66200 time= 0.10294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0031 train_loss= 1.61723 train_acc= 0.81429 val_loss= 1.80165 val_acc= 0.66600 time= 0.12193\nEpoch: 0032 train_loss= 1.64374 train_acc= 0.80000 val_loss= 1.79417 val_acc= 0.66400 time= 0.11894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0033 train_loss= 1.60085 train_acc= 0.85000 val_loss= 1.78656 val_acc= 0.67600 time= 0.14386\nEpoch: 0034 train_loss= 1.59783 train_acc= 0.82857 val_loss= 1.77900 val_acc= 0.67600 time= 0.16391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0035 train_loss= 1.56746 train_acc= 0.85000 val_loss= 1.77145 val_acc= 0.68200 time= 0.14943\nEpoch: 0036 train_loss= 1.57142 train_acc= 0.85714 val_loss= 1.76377 val_acc= 0.68400 time= 0.13692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0037 train_loss= 1.53495 train_acc= 0.87857 val_loss= 1.75596 val_acc= 0.69000 time= 0.10997\nEpoch: 0038 train_loss= 1.52689 train_acc= 0.85000 val_loss= 1.74782 val_acc= 0.69600 time= 0.12562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0039 train_loss= 1.51676 train_acc= 0.85714 val_loss= 1.73937 val_acc= 0.70800 time= 0.14517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0040 train_loss= 1.49229 train_acc= 0.82143 val_loss= 1.73085 val_acc= 0.70800 time= 0.20339\nEpoch: 0041 train_loss= 1.47217 train_acc= 0.87143 val_loss= 1.72235 val_acc= 0.71000 time= 0.12802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0042 train_loss= 1.46521 train_acc= 0.88571 val_loss= 1.71376 val_acc= 0.71400 time= 0.11082\nEpoch: 0043 train_loss= 1.48915 train_acc= 0.85000 val_loss= 1.70508 val_acc= 0.71800 time= 0.09694\nEpoch: 0044"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " train_loss= 1.42744 train_acc= 0.87857 val_loss= 1.69643 val_acc= 0.72200 time= 0.08895\nEpoch: 0045 train_loss= 1.44664 train_acc= 0.85714 val_loss= 1.68788 val_acc= 0.72400 time= 0.10594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0046 train_loss= 1.38420 train_acc= 0.89286 val_loss= 1.67896 val_acc= 0.72800 time= 0.09894\nEpoch: 0047 train_loss= 1.41269 train_acc= 0.86429 val_loss= 1.66994 val_acc= 0.73200 time= 0.10994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0048 train_loss= 1.36044 train_acc= 0.89286 val_loss= 1.66085 val_acc= 0.73600 time= 0.10794\nEpoch: 0049 train_loss= 1.37246 train_acc= 0.87143 val_loss= 1.65166 val_acc= 0.74400 time= 0.09994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0050 train_loss= 1.34976 train_acc= 0.84286 val_loss= 1.64231 val_acc= 0.74600 time= 0.09724\nEpoch: 0051 train_loss= 1.30979 train_acc= 0.88571 val_loss= 1.63305 val_acc= 0.74800 time= 0.10394\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0052 train_loss= 1.34911 train_acc= 0.85714 val_loss= 1.62362 val_acc= 0.75000 time= 0.10111\nEpoch: 0053 train_loss= 1.32759 train_acc= 0.88571 val_loss= 1.61426 val_acc= 0.75200 time= 0.10194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0054 train_loss= 1.28248 train_acc= 0.90714 val_loss= 1.60485 val_acc= 0.75400 time= 0.10195\nEpoch: 0055 train_loss= 1.29519 train_acc= 0.88571 val_loss= 1.59545 val_acc= 0.75600 time= 0.12692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0056 train_loss= 1.28051 train_acc= 0.85000 val_loss= 1.58634 val_acc= 0.76400 time= 0.10094\nEpoch: 0057 train_loss= 1.23875 train_acc= 0.93571 val_loss= 1.57727 val_acc= 0.76400 time= 0.09794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0058 train_loss= 1.23108 train_acc= 0.92143 val_loss= 1.56772 val_acc= 0.77000 time= 0.10994\nEpoch: 0059 train_loss= 1.22798 train_acc= 0.89286 val_loss= 1.55801 val_acc= 0.77400 time= 0.13292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0060 train_loss= 1.22555 train_acc= 0.92857 val_loss= 1.54826 val_acc= 0.77400 time= 0.15292\nEpoch: 0061 train_loss= 1.20502 train_acc= 0.90000 val_loss= 1.53905 val_acc= 0.77400 time= 0.16803\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0062 train_loss= 1.20688 train_acc= 0.90000 val_loss= 1.53007 val_acc= 0.77400 time= 0.21088\nEpoch: 0063 train_loss= 1.12479 train_acc= 0.92143 val_loss= 1.52103 val_acc= 0.77400 time= 0.16090\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0064 train_loss= 1.15719 train_acc= 0.94286 val_loss= 1.51218 val_acc= 0.77600 time= 0.12397\nEpoch: 0065 train_loss= 1.11420 train_acc= 0.91429 val_loss= 1.50361 val_acc= 0.77800 time= 0.11444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0066 train_loss= 1.12602 train_acc= 0.92857 val_loss= 1.49483 val_acc= 0.77800 time= 0.10993\nEpoch: 0067 train_loss= 1.10880 train_acc= 0.94286 val_loss= 1.48608 val_acc= 0.77800 time= 0.11893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0068 train_loss= 1.14477 train_acc= 0.92143 val_loss= 1.47759 val_acc= 0.77800 time= 0.11594\nEpoch: 0069 train_loss= 1.10611 train_acc= 0.92857 val_loss= 1.46927 val_acc= 0.77800 time= 0.11494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0070 train_loss= 1.12255 train_acc= 0.92143 val_loss= 1.46145 val_acc= 0.77600 time= 0.13693\nEpoch: 0071 train_loss= 1.07954 train_acc= 0.89286 val_loss= 1.45367 val_acc= 0.77600 time= 0.12694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0072 train_loss= 1.06249 train_acc= 0.93571 val_loss= 1.44593 val_acc= 0.77600 time= 0.12493\nEpoch: 0073 train_loss= 1.07659 train_acc= 0.92143 val_loss= 1.43838 val_acc= 0.77400 time= 0.11245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0074 train_loss= 1.07699 train_acc= 0.92857 val_loss= 1.43076 val_acc= 0.77400 time= 0.13493\nEpoch: 0075 train_loss= 1.04676 train_acc= 0.91429 val_loss= 1.42319 val_acc= 0.77400 time= 0.10994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0076 train_loss= 1.00799 train_acc= 0.93571 val_loss= 1.41567 val_acc= 0.77600 time= 0.13892\nEpoch: 0077 train_loss= 1.01398 train_acc= 0.94286 val_loss= 1.40805 val_acc= 0.77800 time= 0.11993\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0078 train_loss= 1.02109 train_acc= 0.93571 val_loss= 1.40074 val_acc= 0.77800 time= 0.15492\nEpoch: 0079 train_loss= 1.03909 train_acc= 0.93571 val_loss= 1.39384 val_acc= 0.77800 time= 0.12193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0080 train_loss= 1.00015 train_acc= 0.97143 val_loss= 1.38720 val_acc= 0.77600 time= 0.12400\nEpoch: 0081 train_loss= 1.00614 train_acc= 0.90714 val_loss= 1.38084 val_acc= 0.77600 time= 0.11744\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0082 train_loss= 0.99936 train_acc= 0.92143 val_loss= 1.37477 val_acc= 0.77600 time= 0.12692\nEpoch: 0083 train_loss= 1.00355 train_acc= 0.90000 val_loss= 1.36866 val_acc= 0.77600 time= 0.10794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0084 train_loss= 0.97826 train_acc= 0.92143 val_loss= 1.36263 val_acc= 0.77600 time= 0.10394\nEpoch: 0085 train_loss= 0.96908 train_acc= 0.93571 val_loss= 1.35691 val_acc= 0.77600 time= 0.11194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0086 train_loss= 0.96761 train_acc= 0.92143 val_loss= 1.35139 val_acc= 0.77600 time= 0.13292\nEpoch: 0087 train_loss= 0.97634 train_acc= 0.93571 val_loss= 1.34582 val_acc= 0.77600 time= 0.11891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0088 train_loss= 0.92449 train_acc= 0.92857 val_loss= 1.33998 val_acc= 0.77600 time= 0.12444\nEpoch: 0089 train_loss= 0.93838 train_acc= 0.92857 val_loss= 1.33409 val_acc= 0.77400 time= 0.10794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0090 train_loss= 0.91158 train_acc= 0.92857 val_loss= 1.32840 val_acc= 0.77600 time= 0.11412\nEpoch: 0091 train_loss= 0.93719 train_acc= 0.94286 val_loss= 1.32327 val_acc= 0.77600 time= 0.11624\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0092 train_loss= 0.94949 train_acc= 0.95714 val_loss= 1.31862 val_acc= 0.77600 time= 0.13440\nEpoch: 0093 train_loss= 0.85234 train_acc= 0.95000 val_loss= 1.31410 val_acc= 0.77400 time= 0.12992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0094 train_loss= 0.86402 train_acc= 0.93571 val_loss= 1.30961 val_acc= 0.77400 time= 0.12393\nEpoch: 0095 train_loss= 0.89524 train_acc= 0.95000 val_loss= 1.30514 val_acc= 0.77400 time= 0.12116\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0096 train_loss= 0.87066 train_acc= 0.93571 val_loss= 1.30005 val_acc= 0.77400 time= 0.12793\nEpoch: 0097 train_loss= 0.92863 train_acc= 0.91429 val_loss= 1.29527 val_acc= 0.77400 time= 0.09994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0098 train_loss= 0.92609 train_acc= 0.87857 val_loss= 1.29066 val_acc= 0.77400 time= 0.11209\nEpoch: 0099 train_loss= 0.89037 train_acc= 0.91429 val_loss= 1.28547 val_acc= 0.77600 time= 0.13192\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0100 train_loss= 0.88579 train_acc= 0.92143 val_loss= 1.28054 val_acc= 0.77800 time= 0.10994\nEpoch: 0101 train_loss= 0.86651 train_acc= 0.91429 val_loss= 1.27569 val_acc= 0.77800 time= 0.10305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0102 train_loss= 0.77166 train_acc= 0.96429 val_loss= 1.27073 val_acc= 0.78000 time= 0.10747\nEpoch: 0103 train_loss= 0.82397 train_acc= 0.95714 val_loss= 1.26585 val_acc= 0.77800 time= 0.12193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0104 train_loss= 0.86391 train_acc= 0.95714 val_loss= 1.26094 val_acc= 0.77800 time= 0.13293\nEpoch: 0105 train_loss= 0.86808 train_acc= 0.94286 val_loss= 1.25597 val_acc= 0.77800 time= 0.10294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0106 train_loss= 0.84248 train_acc= 0.95000 val_loss= 1.25098 val_acc= 0.77800 time= 0.11294\nEpoch: 0107 train_loss= 0.84908 train_acc= 0.91429 val_loss= 1.24640 val_acc= 0.77800 time= 0.10794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0108 train_loss= 0.86796 train_acc= 0.92143 val_loss= 1.24264 val_acc= 0.77800 time= 0.09695\nEpoch: 0109 train_loss= 0.86809 train_acc= 0.95000 val_loss= 1.23947 val_acc= 0.77800 time= 0.12693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0110 train_loss= 0.77492 train_acc= 0.97143 val_loss= 1.23592 val_acc= 0.77600 time= 0.16096\nEpoch: 0111 train_loss= 0.84524 train_acc= 0.95000 val_loss= 1.23276 val_acc= 0.77600 time= 0.10694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0112 train_loss= 0.82436 train_acc= 0.95714 val_loss= 1.22940 val_acc= 0.77800 time= 0.13057\nEpoch: 0113 train_loss= 0.83012 train_acc= 0.95000 val_loss= 1.22622 val_acc= 0.78000 time= 0.11893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0114 train_loss= 0.80895 train_acc= 0.92857 val_loss= 1.22306 val_acc= 0.78000 time= 0.15591\nEpoch: 0115 train_loss= 0.80211 train_acc= 0.95000 val_loss= 1.21955 val_acc= 0.78400 time= 0.11494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0116 train_loss= 0.78301 train_acc= 0.96429 val_loss= 1.21619 val_acc= 0.78400 time= 0.10494\nEpoch: 0117 train_loss= 0.78213 train_acc= 0.97143 val_loss= 1.21326 val_acc= 0.78600 time= 0.10994\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0118 train_loss= 0.80806 train_acc= 0.94286 val_loss= 1.21037 val_acc= 0.78200 time= 0.12693\nEpoch: 0119 train_loss= 0.76637 train_acc= 0.95714 val_loss= 1.20691 val_acc= 0.78000 time= 0.10092\nEpoch: 0120 train_loss= 0.78262 train_acc= 0.94286 val_loss= 1.20380 val_acc= 0.78200 time= 0.09795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0121 train_loss= 0.76158 train_acc= 0.93571 val_loss= 1.20087 val_acc= 0.78200 time= 0.12405\nEpoch: 0122 train_loss= 0.77224 train_acc= 0.97143 val_loss= 1.19766 val_acc= 0.78200 time= 0.10294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0123 train_loss= 0.72653 train_acc= 0.99286 val_loss= 1.19419 val_acc= 0.78200 time= 0.11208\nEpoch: 0124 train_loss= 0.78579 train_acc= 0.95000 val_loss= 1.19064 val_acc= 0.78000 time= 0.11195\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0125 train_loss= 0.75468 train_acc= 0.95714 val_loss= 1.18695 val_acc= 0.78000 time= 0.11472\nEpoch: 0126 train_loss= 0.75187 train_acc= 0.95714 val_loss= 1.18305 val_acc= 0.77800 time= 0.11095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0127 train_loss= 0.78744 train_acc= 0.94286 val_loss= 1.17976 val_acc= 0.77600 time= 0.10694\nEpoch: 0128 train_loss= 0.75010 train_acc= 0.94286 val_loss= 1.17618 val_acc= 0.77600 time= 0.11197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0129 train_loss= 0.70196 train_acc= 0.97143 val_loss= 1.17235 val_acc= 0.77600 time= 0.10494\nEpoch: 0130 train_loss= 0.77875 train_acc= 0.94286 val_loss= 1.16897 val_acc= 0.77600 time= 0.12194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0131 train_loss= 0.73701 train_acc= 0.97143 val_loss= 1.16613 val_acc= 0.77600 time= 0.10694\nEpoch: 0132 train_loss= 0.70017 train_acc= 0.95000 val_loss= 1.16354 val_acc= 0.77800 time= 0.11393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0133 train_loss= 0.71598 train_acc= 0.97857 val_loss= 1.16143 val_acc= 0.77800 time= 0.10095\nEpoch: 0134 train_loss= 0.79477 train_acc= 0.94286 val_loss= 1.15989 val_acc= 0.77800 time= 0.10894\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0135 train_loss= 0.72684 train_acc= 0.95714 val_loss= 1.15848 val_acc= 0.77800 time= 0.10593\nEpoch: 0136 train_loss= 0.72221 train_acc= 0.95000 val_loss= 1.15722 val_acc= 0.77800 time= 0.11295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0137 train_loss= 0.76138 train_acc= 0.95000 val_loss= 1.15601 val_acc= 0.77800 time= 0.10301\nEpoch: 0138 train_loss= 0.71077 train_acc= 0.95000 val_loss= 1.15485 val_acc= 0.77800 time= 0.12292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0139 train_loss= 0.71587 train_acc= 0.95714 val_loss= 1.15350 val_acc= 0.77800 time= 0.11403\nEpoch: 0140 train_loss= 0.70428 train_acc= 0.97857 val_loss= 1.15174 val_acc= 0.78000 time= 0.11893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0141 train_loss= 0.71417 train_acc= 0.95000 val_loss= 1.15027 val_acc= 0.77800 time= 0.11313\nEpoch: 0142 train_loss= 0.69698 train_acc= 0.97143 val_loss= 1.14911 val_acc= 0.77800 time= 0.11197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0143 train_loss= 0.74747 train_acc= 0.92143 val_loss= 1.14783 val_acc= 0.77800 time= 0.10494\nEpoch: 0144 train_loss= 0.75270 train_acc= 0.95714 val_loss= 1.14594 val_acc= 0.77800 time= 0.10680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0145 train_loss= 0.68286 train_acc= 0.95714 val_loss= 1.14391 val_acc= 0.77800 time= 0.10594\nEpoch: 0146 train_loss= 0.73422 train_acc= 0.97857 val_loss= 1.14105 val_acc= 0.77800 time= 0.11259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0147 train_loss= 0.71266 train_acc= 0.93571 val_loss= 1.13823 val_acc= 0.77800 time= 0.10895\nEpoch: 0148 train_loss= 0.68726 train_acc= 0.93571 val_loss= 1.13560 val_acc= 0.78200 time= 0.11593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0149 train_loss= 0.70256 train_acc= 0.98571 val_loss= 1.13302 val_acc= 0.78200 time= 0.11794\nEpoch: 0150 train_loss= 0.70240 train_acc= 0.97143 val_loss= 1.13023 val_acc= 0.78000 time= 0.11401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0151 train_loss= 0.64483 train_acc= 0.95000 val_loss= 1.12727 val_acc= 0.78000 time= 0.11390\nEpoch: 0152 train_loss= 0.64050 train_acc= 0.97143 val_loss= 1.12446 val_acc= 0.78000 time= 0.10595\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0153 train_loss= 0.71223 train_acc= 0.95714 val_loss= 1.12179 val_acc= 0.78000 time= 0.11299\nEpoch: 0154 train_loss= 0.68286 train_acc= 0.98571 val_loss= 1.11875 val_acc= 0.78000 time= 0.12064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0155 train_loss= 0.70416 train_acc= 0.95714 val_loss= 1.11599 val_acc= 0.78000 time= 0.11493\nEpoch: 0156 train_loss= 0.71902 train_acc= 0.97143 val_loss= 1.11415 val_acc= 0.77800 time= 0.11095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0157 train_loss= 0.67448 train_acc= 0.97857 val_loss= 1.11215 val_acc= 0.77800 time= 0.10694\nEpoch: 0158 train_loss= 0.66449 train_acc= 0.95714 val_loss= 1.11017 val_acc= 0.78000 time= 0.11096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0159 train_loss= 0.64438 train_acc= 0.96429 val_loss= 1.10892 val_acc= 0.78000 time= 0.11594\nEpoch: 0160 train_loss= 0.64329 train_acc= 0.97143 val_loss= 1.10770 val_acc= 0.78200 time= 0.11693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0161 train_loss= 0.68548 train_acc= 0.97857 val_loss= 1.10604 val_acc= 0.78000 time= 0.11475\nEpoch: 0162 train_loss= 0.67061 train_acc= 0.95000 val_loss= 1.10408 val_acc= 0.78000 time= 0.12793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0163 train_loss= 0.63683 train_acc= 0.97143 val_loss= 1.10300 val_acc= 0.78200 time= 0.15591\nEpoch: 0164 train_loss= 0.66205 train_acc= 0.93571 val_loss= 1.10241 val_acc= 0.78000 time= 0.12193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0165 train_loss= 0.65909 train_acc= 0.97857 val_loss= 1.10189 val_acc= 0.77800 time= 0.11294\nEpoch: 0166 train_loss= 0.65230 train_acc= 0.97857 val_loss= 1.10092 val_acc= 0.78000 time= 0.11393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0167 train_loss= 0.65994 train_acc= 0.94286 val_loss= 1.09960 val_acc= 0.78200 time= 0.10695\nEpoch: 0168 train_loss= 0.68495 train_acc= 0.97143 val_loss= 1.09867 val_acc= 0.78200 time= 0.11793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0169 train_loss= 0.65944 train_acc= 0.97143 val_loss= 1.09731 val_acc= 0.78000 time= 0.11693\nEpoch: 0170 train_loss= 0.66710 train_acc= 0.92857 val_loss= 1.09560 val_acc= 0.78000 time= 0.12493\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0171 train_loss= 0.69614 train_acc= 0.95000 val_loss= 1.09331 val_acc= 0.78200 time= 0.11295\nEpoch: 0172 train_loss= 0.65031 train_acc= 0.97857 val_loss= 1.09166 val_acc= 0.78200 time= 0.12393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0173 train_loss= 0.64674 train_acc= 0.95714 val_loss= 1.09022 val_acc= 0.78400 time= 0.12363\nEpoch: 0174 train_loss= 0.58903 train_acc= 0.97857 val_loss= 1.08896 val_acc= 0.78200 time= 0.11294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0175 train_loss= 0.61592 train_acc= 0.96429 val_loss= 1.08718 val_acc= 0.78200 time= 0.11394\nEpoch: 0176 train_loss= 0.67490 train_acc= 0.95714 val_loss= 1.08439 val_acc= 0.78400 time= 0.10694\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0177 train_loss= 0.64824 train_acc= 0.98571 val_loss= 1.08142 val_acc= 0.78600 time= 0.11891\nEpoch: 0178 train_loss= 0.60770 train_acc= 0.97857 val_loss= 1.07844 val_acc= 0.78400 time= 0.10494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0179 train_loss= 0.64699 train_acc= 0.95000 val_loss= 1.07634 val_acc= 0.78400 time= 0.10694\nEpoch: 0180 train_loss= 0.66983 train_acc= 0.95000 val_loss= 1.07500 val_acc= 0.78600 time= 0.11793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0181 train_loss= 0.64909 train_acc= 0.96429 val_loss= 1.07334 val_acc= 0.78600 time= 0.11593\nEpoch: 0182 train_loss= 0.60040 train_acc= 0.96429 val_loss= 1.07226 val_acc= 0.78600 time= 0.16391\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0183 train_loss= 0.65879 train_acc= 0.95714 val_loss= 1.07135 val_acc= 0.78600 time= 0.13593\nEpoch: 0184 train_loss= 0.64051 train_acc= 0.96429 val_loss= 1.07060 val_acc= 0.78600 time= 0.11361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0185 train_loss= 0.60902 train_acc= 0.96429 val_loss= 1.06962 val_acc= 0.78800 time= 0.13593\nEpoch: 0186 train_loss= 0.63279 train_acc= 0.94286 val_loss= 1.06878 val_acc= 0.78800 time= 0.13292\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0187 train_loss= 0.59645 train_acc= 0.98571 val_loss= 1.06733 val_acc= 0.78600 time= 0.16491\nEpoch: 0188 train_loss= 0.63872 train_acc= 0.94286 val_loss= 1.06527 val_acc= 0.78600 time= 0.11194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0189 train_loss= 0.59015 train_acc= 0.97143 val_loss= 1.06310 val_acc= 0.78800 time= 0.10094\nEpoch: 0190 train_loss= 0.56642 train_acc= 0.97143 val_loss= 1.06111 val_acc= 0.78800 time= 0.11793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0191 train_loss= 0.62657 train_acc= 0.95714 val_loss= 1.05898 val_acc= 0.78600 time= 0.11893\nEpoch: 0192 train_loss= 0.64796 train_acc= 0.95000 val_loss= 1.05727 val_acc= 0.78800 time= 0.10594\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0193 train_loss= 0.62399 train_acc= 0.97857 val_loss= 1.05572 val_acc= 0.78800 time= 0.10370\nEpoch: 0194 train_loss= 0.61233 train_acc= 0.98571 val_loss= 1.05403 val_acc= 0.78600 time= 0.10794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0195 train_loss= 0.59135 train_acc= 0.97857 val_loss= 1.05217 val_acc= 0.78600 time= 0.13192\nEpoch: 0196 train_loss= 0.64115 train_acc= 0.93571 val_loss= 1.05070 val_acc= 0.78800 time= 0.12892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0197 train_loss= 0.58866 train_acc= 0.95714 val_loss= 1.04922 val_acc= 0.78600 time= 0.14992\nEpoch: 0198 train_loss= 0.59634 train_acc= 0.95714 val_loss= 1.04746 val_acc= 0.78600 time= 0.11693\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0199 train_loss= 0.58434 train_acc= 0.98571 val_loss= 1.04561 val_acc= 0.78800 time= 0.09894\nEpoch: 0200 train_loss= 0.61550 train_acc= 0.95714 val_loss= 1.04385 val_acc= 0.79000 time= 0.10294\nOptimization Finished!\n"
     ]
    }
   ],
   "source": [
    "# Create model\n",
    "model = model_func(placeholders, input_dim=features[2][1], logging=True)\n",
    "\n",
    "# Initialize session\n",
    "sess = tf.Session()\n",
    "\n",
    "\n",
    "# Define model evaluation function\n",
    "def evaluate(features, support, labels, mask, placeholders):\n",
    "    t_test = time.time()\n",
    "    feed_dict_val = construct_feed_dict(features, support, labels, mask, placeholders)\n",
    "    outs_val = sess.run([model.loss, model.accuracy], feed_dict=feed_dict_val)\n",
    "    return outs_val[0], outs_val[1], (time.time() - t_test)\n",
    "\n",
    "\n",
    "# Init variables\n",
    "sess.run(tf.global_variables_initializer())\n",
    "\n",
    "cost_val = []\n",
    "\n",
    "# Train model\n",
    "for epoch in range(FLAGS.epochs):\n",
    "\n",
    "    t = time.time()\n",
    "    # Construct feed dictionary\n",
    "    feed_dict = construct_feed_dict(features, support, y_train, train_mask, placeholders)\n",
    "    feed_dict.update({placeholders['dropout']: FLAGS.dropout})\n",
    "\n",
    "    # Training step\n",
    "    outs = sess.run([model.opt_op, model.loss, model.accuracy], feed_dict=feed_dict)\n",
    "\n",
    "    # Validation for early stopping\n",
    "    cost, acc, duration = evaluate(features, support, y_val, val_mask, placeholders)\n",
    "    cost_val.append(cost)\n",
    "\n",
    "    # Print results\n",
    "    print(\"Epoch:\", '%04d' % (epoch + 1), \"train_loss=\", \"{:.5f}\".format(outs[1]),\n",
    "          \"train_acc=\", \"{:.5f}\".format(outs[2]), \"val_loss=\", \"{:.5f}\".format(cost),\n",
    "          \"val_acc=\", \"{:.5f}\".format(acc), \"time=\", \"{:.5f}\".format(time.time() - t))\n",
    "\n",
    "    if epoch > FLAGS.early_stopping and cost_val[-1] > np.mean(cost_val[-(FLAGS.early_stopping+1):-1]):\n",
    "        print(\"Early stopping...\")\n",
    "        break\n",
    "\n",
    "print(\"Optimization Finished!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.13206233, 0.20007877, 0.17057942, 0.14500543, 0.08709805,\n       0.14569305, 0.11948295], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feed_dict_val = construct_feed_dict(features, support, y_test, test_mask, placeholders)\n",
    "# Get the prediction of the test set\n",
    "out = sess.run([model.predict()], feed_dict=feed_dict_val)\n",
    "# First node prediction\n",
    "out[0][1708]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indies\tReal labels\tPredict labels\n1708\t3\t1\n1709\t2\t2\n1710\t2\t2\n1711\t2\t2\n1712\t2\t2\n1713\t0\t0\n1714\t2\t2\n1715\t2\t2\n1716\t2\t2\n1717\t2\t2\n1718\t2\t2\n1719\t2\t2\n1720\t2\t2\n1721\t2\t2\n1722\t2\t2\n1723\t2\t2\n1724\t2\t2\n1725\t2\t2\n1726\t2\t2\n1727\t2\t2\n1728\t3\t3\n1729\t2\t2\n1730\t2\t2\n1731\t2\t2\n1732\t2\t2\n1733\t2\t1\n1734\t2\t2\n1735\t1\t2\n1736\t2\t2\n1737\t2\t2\n1738\t2\t2\n1739\t2\t2\n1740\t2\t2\n1741\t3\t0\n1742\t2\t2\n1743\t2\t2\n1744\t2\t2\n1745\t2\t2\n1746\t2\t2\n1747\t2\t2\n1748\t2\t2\n1749\t2\t2\n1750\t2\t2\n1751\t2\t2\n1752\t2\t2\n1753\t2\t2\n1754\t2\t2\n1755\t2\t2\n1756\t2\t2\n1757\t2\t2\n1758\t2\t2\n1759\t2\t2\n1760\t2\t2\n1761\t2\t2\n1762\t2\t2\n1763\t2\t2\n1764\t5\t2\n1765\t2\t2\n1766\t2\t2\n1767\t1\t1\n1768\t1\t1\n1769\t1\t1\n1770\t1\t1\n1771\t1\t1\n1772\t1\t1\n1773\t1\t1\n1774\t4\t1\n1775\t1\t1\n1776\t1\t1\n1777\t1\t1\n1778\t1\t1\n1779\t1\t1\n1780\t1\t1\n1781\t1\t1\n1782\t1\t1\n1783\t1\t1\n1784\t1\t1\n1785\t4\t4\n1786\t1\t1\n1787\t1\t1\n1788\t1\t1\n1789\t1\t1\n1790\t1\t1\n1791\t1\t1\n1792\t3\t6\n1793\t4\t5\n1794\t4\t4\n1795\t4\t4\n1796\t4\t4\n1797\t1\t1\n1798\t1\t1\n1799\t3\t3\n1800\t1\t1\n1801\t0\t1\n1802\t3\t1\n1803\t0\t6\n1804\t2\t2\n1805\t1\t1\n1806\t3\t3\n1807\t3\t3\n1808\t3\t3\n1809\t3\t3\n1810\t3\t3\n1811\t3\t3\n1812\t3\t3\n1813\t3\t3\n1814\t3\t3\n1815\t3\t3\n1816\t3\t3\n1817\t3\t3\n1818\t3\t3\n1819\t3\t3\n1820\t3\t3\n1821\t3\t3\n1822\t3\t3\n1823\t3\t3\n1824\t5\t5\n1825\t5\t5\n1826\t5\t5\n1827\t5\t5\n1828\t5\t5\n1829\t5\t5\n1830\t2\t2\n1831\t2\t2\n1832\t2\t2\n1833\t2\t2\n1834\t1\t2\n1835\t6\t6\n1836\t6\t6\n1837\t3\t3\n1838\t0\t0\n1839\t0\t0\n1840\t5\t0\n1841\t0\t0\n1842\t5\t5\n1843\t0\t0\n1844\t3\t0\n1845\t5\t0\n1846\t3\t3\n1847\t0\t0\n1848\t0\t0\n1849\t6\t6\n1850\t0\t0\n1851\t6\t0\n1852\t3\t3\n1853\t3\t3\n1854\t1\t3\n1855\t3\t3\n1856\t1\t1\n1857\t3\t3\n1858\t3\t3\n1859\t3\t3\n1860\t3\t3\n1861\t3\t3\n1862\t3\t3\n1863\t3\t3\n1864\t3\t3\n1865\t3\t3\n1866\t3\t3\n1867\t3\t3\n1868\t3\t3\n1869\t3\t4\n1870\t3\t3\n1871\t3\t3\n1872\t3\t3\n1873\t3\t3\n1874\t3\t3\n1875\t3\t3\n1876\t3\t3\n1877\t3\t3\n1878\t5\t5\n1879\t5\t0\n1880\t5\t5\n1881\t5\t5\n1882\t5\t5\n1883\t5\t5\n1884\t5\t5\n1885\t5\t5\n1886\t2\t2\n1887\t2\t2\n1888\t2\t2\n1889\t4\t4\n1890\t4\t4\n1891\t4\t4\n1892\t0\t4\n1893\t3\t4\n1894\t3\t3\n1895\t2\t2\n1896\t5\t5\n1897\t5\t5\n1898\t5\t5\n1899\t5\t5\n1900\t6\t6\n1901\t5\t5\n1902\t5\t5\n1903\t5\t5\n1904\t5\t5\n1905\t0\t6\n1906\t4\t4\n1907\t4\t3\n1908\t4\t0\n1909\t0\t3\n1910\t0\t1\n1911\t5\t0\n1912\t0\t0\n1913\t0\t0\n1914\t6\t6\n1915\t6\t6\n1916\t6\t6\n1917\t6\t6\n1918\t6\t6\n1919\t6\t6\n1920\t0\t6\n1921\t0\t0\n1922\t0\t0\n1923\t0\t0\n1924\t3\t0\n1925\t0\t0\n1926\t0\t0\n1927\t0\t0\n1928\t3\t3\n1929\t3\t4\n1930\t0\t0\n1931\t3\t3\n1932\t3\t3\n1933\t3\t3\n1934\t3\t3\n1935\t3\t3\n1936\t3\t3\n1937\t3\t0\n1938\t3\t0\n1939\t3\t3\n1940\t3\t3\n1941\t3\t3\n1942\t3\t3\n1943\t3\t0\n1944\t3\t3\n1945\t3\t3\n1946\t3\t3\n1947\t3\t3\n1948\t3\t3\n1949\t3\t3\n1950\t3\t3\n1951\t3\t3\n1952\t3\t3\n1953\t5\t5\n1954\t5\t5\n1955\t5\t5\n1956\t5\t5\n1957\t3\t5\n1958\t5\t5\n1959\t5\t5\n1960\t5\t5\n1961\t5\t5\n1962\t5\t5\n1963\t5\t5\n1964\t4\t4\n1965\t4\t4\n1966\t4\t4\n1967\t4\t4\n1968\t4\t4\n1969\t4\t4\n1970\t4\t4\n1971\t4\t4\n1972\t6\t6\n1973\t6\t6\n1974\t5\t5\n1975\t6\t6\n1976\t6\t6\n1977\t3\t0\n1978\t5\t5\n1979\t5\t5\n1980\t5\t5\n1981\t0\t0\n1982\t5\t5\n1983\t0\t4\n1984\t4\t4\n1985\t4\t0\n1986\t3\t3\n1987\t3\t3\n1988\t3\t3\n1989\t2\t3\n1990\t2\t3\n1991\t1\t1\n1992\t3\t3\n1993\t3\t3\n1994\t3\t3\n1995\t3\t3\n1996\t3\t3\n1997\t3\t3\n1998\t5\t1\n1999\t3\t3\n2000\t3\t3\n2001\t4\t4\n2002\t4\t4\n2003\t3\t4\n2004\t3\t3\n2005\t3\t3\n2006\t3\t3\n2007\t3\t3\n2008\t3\t3\n2009\t3\t3\n2010\t0\t6\n2011\t3\t3\n2012\t3\t0\n2013\t6\t0\n2014\t3\t0\n2015\t6\t0\n2016\t0\t6\n2017\t5\t5\n2018\t0\t5\n2019\t0\t5\n2020\t4\t4\n2021\t0\t0\n2022\t6\t6\n2023\t5\t6\n2024\t5\t0\n2025\t0\t0\n2026\t1\t1\n2027\t3\t0\n2028\t3\t6\n2029\t5\t5\n2030\t6\t6\n2031\t5\t6\n2032\t3\t4\n2033\t3\t4\n2034\t4\t4\n2035\t3\t4\n2036\t3\t3\n2037\t3\t3\n2038\t3\t4\n2039\t3\t4\n2040\t4\t4\n2041\t3\t3\n2042\t3\t4\n2043\t4\t4\n2044\t3\t4\n2045\t1\t1\n2046\t1\t1\n2047\t0\t1\n2048\t1\t1\n2049\t0\t0\n2050\t6\t6\n2051\t0\t0\n2052\t0\t0\n2053\t0\t0\n2054\t0\t0\n2055\t0\t0\n2056\t0\t0\n2057\t0\t0\n2058\t5\t2\n2059\t0\t0\n2060\t5\t5\n2061\t5\t5\n2062\t5\t5\n2063\t3\t3\n2064\t3\t3\n2065\t3\t3\n2066\t3\t3\n2067\t3\t3\n2068\t0\t0\n2069\t0\t0\n2070\t0\t0\n2071\t2\t0\n2072\t0\t0\n2073\t0\t0\n2074\t0\t0\n2075\t3\t3\n2076\t3\t3\n2077\t3\t3\n2078\t3\t1\n2079\t1\t1\n2080\t1\t1\n2081\t1\t1\n2082\t1\t1\n2083\t2\t2\n2084\t1\t1\n2085\t1\t1\n2086\t1\t1\n2087\t1\t1\n2088\t1\t1\n2089\t0\t1\n2090\t1\t1\n2091\t3\t3\n2092\t1\t1\n2093\t1\t1\n2094\t1\t1\n2095\t1\t1\n2096\t1\t1\n2097\t0\t0\n2098\t0\t0\n2099\t0\t0\n2100\t5\t6\n2101\t5\t6\n2102\t5\t0\n2103\t5\t0\n2104\t3\t3\n2105\t5\t0\n2106\t1\t1\n2107\t1\t1\n2108\t3\t0\n2109\t6\t6\n2110\t6\t6\n2111\t5\t6\n2112\t6\t6\n2113\t2\t2\n2114\t3\t3\n2115\t3\t3\n2116\t0\t0\n2117\t3\t3\n2118\t3\t3\n2119\t3\t4\n2120\t4\t4\n2121\t4\t4\n2122\t4\t4\n2123\t4\t4\n2124\t3\t4\n2125\t3\t4\n2126\t3\t4\n2127\t4\t4\n2128\t3\t3\n2129\t3\t4\n2130\t4\t4\n2131\t0\t0\n2132\t6\t6\n2133\t0\t0\n2134\t6\t6\n2135\t6\t6\n2136\t0\t0\n2137\t0\t0\n2138\t3\t3\n2139\t3\t3\n2140\t3\t3\n2141\t3\t3\n2142\t3\t3\n2143\t1\t1\n2144\t1\t1\n2145\t1\t1\n2146\t3\t3\n2147\t3\t3\n2148\t3\t3\n2149\t3\t4\n2150\t5\t2\n2151\t6\t6\n2152\t3\t3\n2153\t4\t0\n2154\t6\t0\n2155\t0\t0\n2156\t0\t0\n2157\t6\t6\n2158\t6\t6\n2159\t6\t6\n2160\t6\t6\n2161\t6\t6\n2162\t3\t3\n2163\t3\t3\n2164\t6\t6\n2165\t6\t6\n2166\t5\t6\n2167\t2\t2\n2168\t1\t2\n2169\t2\t1\n2170\t1\t0\n2171\t0\t0\n2172\t0\t0\n2173\t6\t5\n2174\t6\t5\n2175\t2\t3\n2176\t3\t3\n2177\t3\t6\n2178\t5\t0\n2179\t0\t0\n2180\t0\t0\n2181\t0\t0\n2182\t0\t0\n2183\t0\t0\n2184\t5\t5\n2185\t5\t5\n2186\t0\t0\n2187\t3\t4\n2188\t5\t0\n2189\t0\t0\n2190\t6\t6\n2191\t3\t3\n2192\t6\t6\n2193\t0\t0\n2194\t0\t0\n2195\t0\t6\n2196\t0\t0\n2197\t0\t0\n2198\t0\t0\n2199\t0\t0\n2200\t0\t0\n2201\t0\t0\n2202\t0\t0\n2203\t0\t0\n2204\t3\t3\n2205\t3\t3\n2206\t3\t3\n2207\t3\t3\n2208\t1\t1\n2209\t6\t6\n2210\t1\t1\n2211\t0\t4\n2212\t3\t3\n2213\t3\t3\n2214\t3\t3\n2215\t3\t3\n2216\t3\t3\n2217\t6\t6\n2218\t1\t1\n2219\t0\t0\n2220\t2\t2\n2221\t2\t2\n2222\t4\t4\n2223\t4\t4\n2224\t4\t4\n2225\t4\t4\n2226\t4\t4\n2227\t5\t5\n2228\t6\t6\n2229\t3\t3\n2230\t3\t3\n2231\t0\t4\n2232\t0\t0\n2233\t0\t0\n2234\t0\t0\n2235\t5\t5\n2236\t4\t4\n2237\t4\t4\n2238\t4\t4\n2239\t4\t4\n2240\t4\t4\n2241\t3\t3\n2242\t3\t3\n2243\t3\t3\n2244\t3\t3\n2245\t3\t3\n2246\t0\t3\n2247\t3\t3\n2248\t4\t4\n2249\t4\t4\n2250\t4\t4\n2251\t1\t1\n2252\t1\t1\n2253\t3\t3\n2254\t1\t1\n2255\t1\t6\n2256\t5\t1\n2257\t1\t1\n2258\t3\t3\n2259\t4\t4\n2260\t4\t4\n2261\t4\t4\n2262\t4\t4\n2263\t4\t0\n2264\t4\t4\n2265\t4\t4\n2266\t0\t0\n2267\t0\t0\n2268\t0\t4\n2269\t5\t5\n2270\t5\t5\n2271\t5\t5\n2272\t5\t5\n2273\t5\t5\n2274\t0\t0\n2275\t5\t5\n2276\t3\t0\n2277\t0\t0\n2278\t6\t6\n2279\t2\t2\n2280\t0\t0\n2281\t5\t5\n2282\t3\t6\n2283\t3\t3\n2284\t5\t5\n2285\t5\t5\n2286\t5\t5\n2287\t5\t5\n2288\t5\t5\n2289\t4\t4\n2290\t4\t4\n2291\t0\t4\n2292\t4\t4\n2293\t0\t6\n2294\t4\t4\n2295\t0\t0\n2296\t3\t3\n2297\t4\t4\n2298\t4\t4\n2299\t4\t4\n2300\t1\t1\n2301\t3\t4\n2302\t3\t4\n2303\t3\t3\n2304\t3\t3\n2305\t3\t3\n2306\t4\t3\n2307\t2\t2\n2308\t3\t3\n2309\t3\t3\n2310\t3\t3\n2311\t0\t0\n2312\t0\t0\n2313\t2\t1\n2314\t3\t1\n2315\t3\t3\n2316\t3\t3\n2317\t3\t3\n2318\t1\t1\n2319\t1\t3\n2320\t3\t3\n2321\t0\t0\n2322\t1\t1\n2323\t4\t5\n2324\t1\t1\n2325\t1\t1\n2326\t1\t5\n2327\t1\t1\n2328\t1\t1\n2329\t1\t1\n2330\t0\t0\n2331\t1\t1\n2332\t0\t4\n2333\t0\t0\n2334\t2\t2\n2335\t4\t4\n2336\t4\t4\n2337\t4\t4\n2338\t3\t3\n2339\t3\t3\n2340\t3\t3\n2341\t4\t3\n2342\t0\t0\n2343\t3\t3\n2344\t3\t3\n2345\t3\t4\n2346\t3\t4\n2347\t0\t0\n2348\t3\t4\n2349\t3\t4\n2350\t4\t4\n2351\t4\t4\n2352\t4\t4\n2353\t4\t4\n2354\t4\t3\n2355\t4\t0\n2356\t0\t0\n2357\t4\t0\n2358\t3\t3\n2359\t2\t3\n2360\t0\t3\n2361\t3\t3\n2362\t4\t4\n2363\t5\t5\n2364\t0\t0\n2365\t2\t2\n2366\t2\t2\n2367\t3\t3\n2368\t3\t3\n2369\t3\t3\n2370\t3\t3\n2371\t3\t3\n2372\t2\t3\n2373\t3\t0\n2374\t5\t5\n2375\t5\t5\n2376\t4\t4\n2377\t1\t1\n2378\t4\t4\n2379\t4\t4\n2380\t4\t4\n2381\t3\t4\n2382\t4\t4\n2383\t4\t4\n2384\t0\t0\n2385\t4\t3\n2386\t4\t4\n2387\t4\t4\n2388\t5\t6\n2389\t2\t2\n2390\t2\t2\n2391\t2\t2\n2392\t2\t2\n2393\t4\t4\n2394\t6\t0\n2395\t6\t6\n2396\t6\t6\n2397\t6\t0\n2398\t3\t3\n2399\t4\t4\n2400\t4\t4\n2401\t4\t4\n2402\t1\t3\n2403\t3\t3\n2404\t0\t0\n2405\t3\t5\n2406\t3\t4\n2407\t5\t5\n2408\t0\t0\n2409\t2\t3\n2410\t3\t3\n2411\t3\t3\n2412\t3\t3\n2413\t3\t2\n2414\t3\t3\n2415\t2\t2\n2416\t4\t4\n2417\t4\t4\n2418\t0\t0\n2419\t0\t0\n2420\t3\t3\n2421\t2\t2\n2422\t6\t6\n2423\t6\t0\n2424\t0\t0\n2425\t3\t0\n2426\t3\t3\n2427\t3\t5\n2428\t5\t5\n2429\t1\t1\n2430\t3\t3\n2431\t4\t4\n2432\t4\t4\n2433\t2\t1\n2434\t4\t4\n2435\t4\t4\n2436\t4\t6\n2437\t3\t0\n2438\t3\t0\n2439\t2\t2\n2440\t2\t2\n2441\t2\t2\n2442\t2\t2\n2443\t2\t2\n2444\t2\t2\n2445\t2\t2\n2446\t2\t2\n2447\t2\t2\n2448\t2\t2\n2449\t0\t0\n2450\t2\t2\n2451\t2\t2\n2452\t2\t2\n2453\t0\t0\n2454\t6\t6\n2455\t6\t6\n2456\t5\t2\n2457\t6\t6\n2458\t6\t6\n2459\t3\t3\n2460\t2\t2\n2461\t6\t6\n2462\t3\t2\n2463\t4\t4\n2464\t4\t4\n2465\t4\t4\n2466\t2\t2\n2467\t6\t5\n2468\t6\t5\n2469\t0\t2\n2470\t0\t2\n2471\t3\t3\n2472\t0\t4\n2473\t4\t4\n2474\t4\t4\n2475\t3\t3\n2476\t2\t2\n2477\t3\t3\n2478\t1\t1\n2479\t6\t6\n2480\t6\t6\n2481\t5\t5\n2482\t3\t0\n2483\t4\t4\n2484\t3\t4\n2485\t5\t6\n2486\t3\t3\n2487\t1\t1\n2488\t1\t1\n2489\t3\t4\n2490\t4\t0\n2491\t5\t5\n2492\t2\t2\n2493\t3\t3\n2494\t3\t3\n2495\t3\t3\n2496\t4\t0\n2497\t5\t5\n2498\t4\t4\n2499\t0\t0\n2500\t3\t3\n2501\t3\t3\n2502\t0\t0\n2503\t2\t2\n2504\t1\t1\n2505\t1\t1\n2506\t5\t5\n2507\t2\t2\n2508\t3\t3\n2509\t3\t3\n2510\t5\t5\n2511\t0\t0\n2512\t2\t2\n2513\t3\t3\n2514\t2\t2\n2515\t2\t2\n2516\t5\t5\n2517\t5\t5\n2518\t4\t4\n2519\t3\t3\n2520\t4\t4\n2521\t3\t3\n2522\t2\t2\n2523\t2\t2\n2524\t4\t4\n2525\t2\t2\n2526\t4\t4\n2527\t5\t5\n2528\t5\t5\n2529\t3\t3\n2530\t2\t2\n2531\t3\t3\n2532\t1\t1\n2533\t0\t3\n2534\t3\t3\n2535\t3\t3\n2536\t4\t4\n2537\t5\t5\n2538\t4\t4\n2539\t3\t3\n2540\t3\t3\n2541\t3\t3\n2542\t3\t3\n2543\t3\t3\n2544\t0\t0\n2545\t1\t0\n2546\t2\t2\n2547\t4\t4\n2548\t4\t4\n2549\t4\t4\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2550\t3\t3\n2551\t3\t3\n2552\t3\t3\n2553\t5\t6\n2554\t2\t2\n2555\t3\t3\n2556\t2\t2\n2557\t2\t2\n2558\t2\t2\n2559\t3\t3\n2560\t2\t2\n2561\t2\t0\n2562\t0\t6\n2563\t4\t4\n2564\t4\t4\n2565\t3\t4\n2566\t3\t4\n2567\t3\t4\n2568\t3\t3\n2569\t3\t2\n2570\t3\t3\n2571\t3\t2\n2572\t3\t3\n2573\t3\t3\n2574\t3\t3\n2575\t0\t0\n2576\t0\t0\n2577\t3\t3\n2578\t0\t3\n2579\t3\t3\n2580\t0\t3\n2581\t2\t2\n2582\t3\t3\n2583\t4\t4\n2584\t1\t2\n2585\t2\t2\n2586\t5\t3\n2587\t4\t4\n2588\t3\t3\n2589\t3\t3\n2590\t3\t4\n2591\t1\t1\n2592\t5\t5\n2593\t3\t3\n2594\t4\t4\n2595\t3\t3\n2596\t2\t2\n2597\t2\t2\n2598\t1\t1\n2599\t3\t3\n2600\t3\t2\n2601\t3\t3\n2602\t3\t3\n2603\t3\t3\n2604\t6\t6\n2605\t3\t3\n2606\t3\t2\n2607\t3\t2\n2608\t6\t6\n2609\t3\t3\n2610\t3\t3\n2611\t3\t0\n2612\t2\t2\n2613\t3\t3\n2614\t2\t2\n2615\t4\t3\n2616\t2\t2\n2617\t4\t5\n2618\t2\t2\n2619\t2\t2\n2620\t1\t0\n2621\t5\t5\n2622\t6\t6\n2623\t4\t4\n2624\t3\t3\n2625\t3\t3\n2626\t3\t3\n2627\t2\t2\n2628\t5\t5\n2629\t3\t3\n2630\t3\t3\n2631\t4\t4\n2632\t3\t3\n2633\t3\t3\n2634\t3\t3\n2635\t3\t3\n2636\t3\t3\n2637\t4\t4\n2638\t6\t6\n2639\t0\t6\n2640\t3\t5\n2641\t2\t2\n2642\t2\t2\n2643\t2\t2\n2644\t5\t0\n2645\t4\t4\n2646\t4\t4\n2647\t4\t4\n2648\t4\t4\n2649\t6\t6\n2650\t3\t3\n2651\t2\t2\n2652\t2\t2\n2653\t0\t0\n2654\t2\t6\n2655\t2\t3\n2656\t2\t6\n2657\t2\t2\n2658\t2\t2\n2659\t3\t3\n2660\t4\t0\n2661\t4\t4\n2662\t4\t4\n2663\t3\t3\n2664\t3\t3\n2665\t4\t4\n2666\t4\t4\n2667\t3\t3\n2668\t3\t3\n2669\t3\t0\n2670\t4\t4\n2671\t4\t4\n2672\t4\t4\n2673\t4\t4\n2674\t4\t4\n2675\t4\t4\n2676\t3\t3\n2677\t4\t4\n2678\t4\t4\n2679\t4\t4\n2680\t4\t4\n2681\t4\t4\n2682\t4\t4\n2683\t4\t4\n2684\t4\t4\n2685\t2\t2\n2686\t3\t3\n2687\t3\t3\n2688\t3\t3\n2689\t2\t2\n2690\t6\t3\n2691\t2\t2\n2692\t3\t6\n2693\t3\t3\n2694\t4\t4\n2695\t4\t4\n2696\t3\t3\n2697\t3\t3\n2698\t3\t3\n2699\t3\t3\n2700\t3\t3\n2701\t3\t3\n2702\t0\t3\n2703\t3\t3\n2704\t3\t2\n2705\t3\t5\n2706\t3\t3\n2707\t3\t3\n"
     ]
    }
   ],
   "source": [
    "# Compare real labels and predict labels \n",
    "print('Indies' + '\\t' + 'Real labels' + '\\t' + 'Predict labels')\n",
    "for i in range(1708, 2708):\n",
    "    print(str(i) + '\\t' + str(np.argmax(y_test[i])) + '\\t' + str(np.argmax(out[0][i])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set results: cost= 1.00631 accuracy= 0.80900 time= 0.05297\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "test_cost, test_acc, test_duration = evaluate(features, support, y_test, test_mask, placeholders)\n",
    "print(\"Test set results:\", \"cost=\", \"{:.5f}\".format(test_cost),\n",
    "      \"accuracy=\", \"{:.5f}\".format(test_acc), \"time=\", \"{:.5f}\".format(test_duration))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
